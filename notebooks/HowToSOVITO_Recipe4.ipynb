{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Recipe 4: Recreating turntable animation of a model\"\n",
    "subtitle: \"How to Script with OVITO\"\n",
    "code-links:\n",
    "    - text: Notebook\n",
    "      icon: file-code\n",
    "      href: https://stefanbringuier.github.io/HowToSOVITO/notebooks/HowToSOVITO_Recipe4.ipynb\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/stefanbringuier/HowToSOVITO/blob/main/notebooks/HowToSOVITO_Recipe4.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the tutorials on the [GUI OVITO documentation](https://www.ovito.org/manual/tutorials/turntable_animation.html#tutorials-turntable-animation) you find a tutorial showing how to create a turntable animation of a model. If you have access to the [Pro OVITO](https://www.ovito.org/#proFeatures) version, they generating the script to batch run this process on several different structures is very straightforward. However, if you only have the [Basic OVITO](https://www.ovito.org/#download) version, you cannot. Therefore having using SOVITO is the only option. \n",
    "\n",
    "In this notebook we are going to recreate almost the same animation but by scripting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install -U ovito\n",
    "! pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import OVITO Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ovito.io import import_file\n",
    "from ovito.modifiers import AffineTransformationModifier\n",
    "from ovito.pipeline import StaticSource, Pipeline\n",
    "from ovito.modifiers import PythonScriptModifier\n",
    "from ovito.vis import TachyonRenderer\n",
    "from ovito.vis import Viewport\n",
    "import numpy as np\n",
    "from imageio.v3 import imread\n",
    "from imageio import mimsave\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Remote import file\n",
    "\n",
    "::: {.callout-tip}\n",
    "In previous tutorials I used command line `wget` to download the file, however, the `import_file` function has the ability to do remote fetch simply by using a url\n",
    ":::\n",
    "\n",
    "We import the file and then get the data via the `compute` method of the `pipeline` for the frame of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_file = \"https://gitlab.com/ovito-org/ovito-sample-data/-/raw/04f075def623f25ae1a2d8363a4dcf6e90a0f91a/NetCDF/C60_impact.nc\"\n",
    "pipeline=import_file(remote_file,input_format=\"netcdf/amber\")\n",
    "\n",
    "nframes = pipeline.source.num_frames\n",
    "data = pipeline.compute(nframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Static pipeline\n",
    "\n",
    "Now we create a new, static, pipeline from the `data` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_pipeline = Pipeline(source=StaticSource(data=data))\n",
    "static_pipeline.add_to_scene()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some code for color coding (optional)\n",
    "\n",
    "Just so that the rendered turnable animation is similar to the original version, I'm adding some code here to modify the particle color based on the atomic number, Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    1: (1.0, 1.0, 0.0),  # Yellow for Z=1\n",
    "    6: (0.2, 0.4, 0.7)   # Blue for Z=6\n",
    "}\n",
    "\n",
    "def color_particles_based_on_z(frame, data):\n",
    "    if 'Color' not in data.particles.keys():\n",
    "        data.particles_.create_property('Color', \n",
    "                                        data=np.zeros((data.particles.count, 3), \n",
    "                                                      dtype=np.float32),\n",
    "                                                      )\n",
    "    # Access the atomic number property\n",
    "    z_property = data.particles['Z'].array  \n",
    "    colors = data.particles['Color'].marray\n",
    "    \n",
    "    # Assign colors based on atomic number using the color map\n",
    "    for z, color in color_map.items():\n",
    "        mask = (z_property == z)\n",
    "        colors[mask] = color\n",
    "\n",
    "\n",
    "static_pipeline.modifiers.append(PythonScriptModifier(function=color_particles_based_on_z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Translating center of rotation\n",
    "\n",
    "As with the GUI OVITO tutorial, we need to move the rotation center via the `AffineTransformationModifier`. We specify this translation using the transformation matrix `kwarg`, where the last column is the translation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_matrix = [[1.0, 0.0, 0.0, -0.5],\n",
    "                         [0.0, 1.0, 0.0, -0.5],\n",
    "                         [0.0, 0.0, 1.0, -0.5]]\n",
    "static_pipeline.modifiers.append(AffineTransformationModifier(\n",
    "    transformation=transformation_matrix,\n",
    "    reduced_coords=True,  \n",
    "    )\n",
    ")\n",
    "\n",
    "static_pipeline.compute();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Viewport\n",
    "\n",
    "One key difference in the approach used in the GUI OVITO implementation, is we cannot use[^1 At least to my knowledge.] the `Viewport.render_anim` call because we are not rendering simulation scenes but are just take snapshots of a single scene with a different camera location. Thus we need to write a function to adjust the viewport as we desire. My approach just uses a rotation angle in the x-y plane and then a fixed angle in the azimuthal direction. The distance from the origin is set by `r` which you can change based on your need.\n",
    "\n",
    ":::{.callout-note}\n",
    "I'm not sure the field of view variable `fov` does anything here, since it appears this doesn't mean anything for a `Perspective` type of view.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewport = Viewport(fov=30)\n",
    "viewport.type = Viewport.Type.Perspective\n",
    "\n",
    "def update_camera_settings(frame, total_frames, r=125):\n",
    "    angle = (frame / total_frames) * 2 * np.pi\n",
    "    \n",
    "    # Calculate the new camera position for the circular orbit\n",
    "    rx = r * np.sin(angle)\n",
    "    ry = r * np.cos(angle)\n",
    "    rz = r / np.sqrt(2) # Camera at 45 degree in z-azimuthal\n",
    "    camera_pos = (rx, ry, rz)\n",
    "    \n",
    "    dir_vector = (-camera_pos[0], -camera_pos[1], -camera_pos[2])\n",
    "    # Normalize the direction vector\n",
    "    magnitude = np.linalg.norm(dir_vector)\n",
    "    camera_dir = (dir_vector[0]/magnitude, dir_vector[1]/magnitude, dir_vector[2]/magnitude)\n",
    "    \n",
    "    return camera_pos, camera_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Render Animation of scene\n",
    "\n",
    "The key difference in this animation is that we are moving the camera around the static scene/frame to generate the perspective of a rotating object. To achieve this we loop over the number of camera positions (i.e., animation length) update the camera position and direction vector, render the scene to a temporary image file, and then use the `imageio` package to create an animation from all the rendered scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_length = 100\n",
    "renderer = TachyonRenderer(\n",
    "    ambient_occlusion=True,  \n",
    "    ambient_occlusion_brightness=0.8,  \n",
    "    antialiasing=True,  \n",
    "    antialiasing_samples=64,  \n",
    "    direct_light=True,  \n",
    "    direct_light_intensity=0.9, \n",
    "    shadows=True,  \n",
    "    depth_of_field=False, \n",
    "    focal_length=40.0,  \n",
    "    aperture=0.01  \n",
    ")\n",
    "image_paths = []\n",
    "\n",
    "for frame in range(animation_length):\n",
    "    camera_pos, camera_dir = update_camera_settings(frame, animation_length)\n",
    "    viewport.camera_pos = camera_pos\n",
    "    viewport.camera_dir = camera_dir\n",
    "    \n",
    "    filename = f\"temp_frame_{frame:04d}.png\"\n",
    "    image_paths.append(filename)  # Store for later deletion\n",
    "    viewport.render_image(filename=filename, size=(600, 400), renderer=renderer)\n",
    "\n",
    "# Create a GIF from the images\n",
    "gif_filename = 'recipe4_animation.gif'\n",
    "images = [imread(filename) for filename in image_paths]\n",
    "mimsave(gif_filename, images, fps=25, loop=0)\n",
    "\n",
    "# Delete the temporary images\n",
    "for filename in image_paths:\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from IPython.display import Image\n",
    "    Image(open(fname, 'rb').read())\n",
    "except ImportError:\n",
    "    \"Assuming local run.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Reproducing the turnable animation in the OVITO Basic GUI tutorial.](../resources/recipe4_animation.gif){#fig-turnable}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "A few things to note:\n",
    "\n",
    "1. The perspective view is a little different from that shown in the [original](https://www.ovito.org/manual/_images/turntable.gif) mainly because I'm not exactly sure the settings of the camera. You will need to adjust the settings based on your data.\n",
    "2. In my opinion this recipe may bit a bit unessecary, because with OVITO 3.10 and above you can use the [glTF](https://www.ovito.org/docs/dev/reference/file_formats/output/gltf.html#file-formats-output-gltf) format which creates 3D models that can be animated to rotate and are manipulatable. Furthermore, you can use the [`ovito_to_ase`](https://www.ovito.org/docs/dev/python/modules/ovito_io_ase.html#module-ovito.io.ase) call to create an ASE Atoms object and then use ASE io to save to html and use X3DOM [@Bringuier27FEB2024].\n",
    "\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
