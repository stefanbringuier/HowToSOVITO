[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "How To Script with OVITO",
    "section": "",
    "text": "OVITO is a visualization software for computational chemistry and materials science (Stukowski 2009). Its primarily used through a graphical user interface (GUI), but it has a standalone python scripting library that allows for full fledge use of all OVITO capabilities1. Its very powerful approach that enables manipulation of atomic simulation data to create beautiful visualizations.\n1 No need for Pro subscription2 I will use the acronym SOVITO regularly3 Both Basic and Pro versionsThis site is a rendering from a collection of Google Colab/Jupyter notebooks that show recipes for how to perform visualization and data analysis using python scripting OVITO (SOVITO2) interface. This is not a “How to run LAMMPS” nor a guide on how to perform specific analysis. Its merely how one would use SOVITO to get “pre-defined” outcomes similar to those in the GUI3.\nIn addition to these recipes, you can find examples on the OVITO scripting documentation here. Some of the example scripts there can be ran on there own, while the modifier, scripts are intended to be combined with a pipeline object.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "How To Script with OVITO",
    "section": "",
    "text": "OVITO is a visualization software for computational chemistry and materials science (Stukowski 2009). Its primarily used through a graphical user interface (GUI), but it has a standalone python scripting library that allows for full fledge use of all OVITO capabilities1. Its very powerful approach that enables manipulation of atomic simulation data to create beautiful visualizations.\n1 No need for Pro subscription2 I will use the acronym SOVITO regularly3 Both Basic and Pro versionsThis site is a rendering from a collection of Google Colab/Jupyter notebooks that show recipes for how to perform visualization and data analysis using python scripting OVITO (SOVITO2) interface. This is not a “How to run LAMMPS” nor a guide on how to perform specific analysis. Its merely how one would use SOVITO to get “pre-defined” outcomes similar to those in the GUI3.\nIn addition to these recipes, you can find examples on the OVITO scripting documentation here. Some of the example scripts there can be ran on there own, while the modifier, scripts are intended to be combined with a pipeline object.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#installing-ovito-python-scripting",
    "href": "index.html#installing-ovito-python-scripting",
    "title": "How To Script with OVITO",
    "section": "Installing OVITO python scripting",
    "text": "Installing OVITO python scripting\nYou don’t need to install the GUI version of OVITO to use the code shown on this site. There are two options:\npip\npip install -U ovito\nConda\nconda install --strict-channel-priority -c https://conda.ovito.org -c conda-forge ovito=3\n\n\n\n\n\n\nNote\n\n\n\nMost of the notebooks inlcude cell magic escapes to pip install OVITO.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#notes-on-rendering",
    "href": "index.html#notes-on-rendering",
    "title": "How To Script with OVITO",
    "section": "Notes on Rendering",
    "text": "Notes on Rendering\nOVITO has the following options for rendering images:\n\nOpenGL\nTachyon\nOSPRay\nAnari4 (CUDA GPU)\n\n4 This is an experimental renderer and I had trouble getting it to workBoth 1 and 4 are hardware based while 2-3 are software ray tracing programs. For quick rendered images, I find that 1 is the best, however since I’m running the notebooks on Google Colab or JupyterLab in a headless configuration I couldn’t get OpenGL to work so I used 2 or 3.\nIn general, the choice of render is based on need for speed and preference for the stylistic aspects of redendering atomistic simulations. There is no “best” choice for everyone, just use what you like. Therefore in the notebooks just change the render to what you would prefer.\n\n\n\n\n\n\nTip\n\n\n\nThe developer(s) of OVITO really try to provide very modern tools for visualization. This includes the ability to use glTF, which is a web standard for displaying 3D models. This means you can display your simulation cell with analysis colorings and make them maninuplateable.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html#notebooks",
    "href": "index.html#notebooks",
    "title": "How To Script with OVITO",
    "section": "Notebooks",
    "text": "Notebooks\nMost of the notebooks have been drafted using Google Colab which is a custom version of Jupyter notebooks. The notebooks are then rendered with Quarto to produce this website. This makes it so the reader can either copy code snippets in whatever python setup they prefer. Could be VSCode, JupyterLab, Google Colab, etc.\nOn each recipe page you should find a links at the top and side to view the notebook version of the webpage displayed.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html",
    "href": "notebooks/HowToSOVITO_Recipe3.html",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "",
    "text": "When you have grain boundaries it is convenient to be able to distinguish those atoms from the bulk. One way to do so is using a order or structural parameter that captures some information about the local environment. OVITO has a few different options built in that enable characterize whether an atom is in an FCC, BCC, HCP, or other structure. Here I’ll be working with the LAMMPS dump file from the example in (Bringuier 2015) which reproduces the results from (Cahn, Mishin, and Suzuki 2006).\n%%capture\n! pip install -U ovito",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html#import-ovito-modules",
    "href": "notebooks/HowToSOVITO_Recipe3.html#import-ovito-modules",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "Import OVITO modules",
    "text": "Import OVITO modules\n\nfrom ovito.io import import_file\nfrom ovito.vis import Viewport\nfrom ovito.modifiers import CommonNeighborAnalysisModifier, CalculateDisplacementsModifier\nfrom ovito.modifiers import ExpressionSelectionModifier, DeleteSelectedModifier, InvertSelectionModifier\nfrom ovito.modifiers import AssignColorModifier\nfrom ovito.vis import VectorVis\nfrom ovito.vis import OSPRayRenderer",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html#step-1-download-and-import-file",
    "href": "notebooks/HowToSOVITO_Recipe3.html#step-1-download-and-import-file",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "Step 1: Download and import file",
    "text": "Step 1: Download and import file\n\n\n\n\n\n\nNote\n\n\n\nThis LAMMPS dump file was from a 2D simulation but the symmetry is 3D so we reset the PBC for all directions. I’m doing this because I want to maintain the correct structural analysis results.\n\n\n\n%%capture\n! wget 'https://drive.google.com/uc?id=1Id0D6rfHxJOTuPx2RVAYkm2yRBBgIzSE&export=download' -O dump.Cu_Bicrystal_Shear_298K.gz\npipeline = import_file('dump.Cu_Bicrystal_Shear_298K.gz',input_format='lammps/dump')\npipeline.source.data.cell_.pbc = (True, True, True)",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html#step-2-perform-structural-analysis-and-calculate-displacement-vectors",
    "href": "notebooks/HowToSOVITO_Recipe3.html#step-2-perform-structural-analysis-and-calculate-displacement-vectors",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "Step 2: Perform structural analysis and calculate displacement vectors",
    "text": "Step 2: Perform structural analysis and calculate displacement vectors\nI will use the CommonNeighborAnalysisModifier which provides standard structural analysis to identify the closed-packing of the crystal (e.g., FCC, BCC, HCP, ICO).\nOnce the structure modifier is used, I will color code just the atoms that are of StructureType == which corresponds to “Other”. To do this we can use the modifier to select these atoms and then color code.\n\npipeline.modifiers.append(CommonNeighborAnalysisModifier())\n\n# Select particles based on structure type and position\nexpression = 'StructureType != 0 || (Position.Z &gt; CellSize.Z-5 || Position.Z &lt; 5.0 )'\npipeline.modifiers.append(ExpressionSelectionModifier(expression=expression))\n\n# Color the selected particles\npipeline.modifiers.append(AssignColorModifier(color=(0.0, 0.5, 1.0))) \npipeline.modifiers.append(InvertSelectionModifier())\n# Now color the GB atoms\npipeline.modifiers.append(AssignColorModifier(color=(0.8, 0.5, 0.2)))\npipeline.modifiers.append(InvertSelectionModifier())\n\npipeline.add_to_scene()",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html#step-3-render-first-animation",
    "href": "notebooks/HowToSOVITO_Recipe3.html#step-3-render-first-animation",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "Step 3: Render first animation",
    "text": "Step 3: Render first animation\n\nvp = Viewport(type=Viewport.Type.Ortho)\nvp.camera_dir = [-1, 0, 0]\nvp.zoom_all()\nrenderer = OSPRayRenderer(\n    ambient_light_enabled=True,\n    denoising_enabled=True,\n    direct_light_enabled=True,\n    direct_light_intensity=1.0,\n    material_shininess=10.0,\n    material_specular_brightness=0.02\n)\n\nfname = \"Cu_Bicrystal_Shear_298K_ColorCoding.gif\"\nvp.render_anim(size=(600,400), \n               filename=fname, \n               renderer=renderer)\n\n\n\n\n\n\n\nNote\n\n\n\nThe code below is to allow for displaying rendered images in Google Colab.\n\n\n\ntry:\n    import google.colab\n    from IPython.display import Image\n    Image(open(fname, 'rb').read())\nexcept ImportError:\n    \"Assuming local run.\"\n\n\n\n\n\n\n\nFigure 1: Grain boundary color coded.",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html#step-4-displacement-vectors",
    "href": "notebooks/HowToSOVITO_Recipe3.html#step-4-displacement-vectors",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "Step 4: Displacement vectors",
    "text": "Step 4: Displacement vectors\nWe may want to show how the atoms at the grain boundary are moving with respect to the shear force. We can do this with the displacement vectors. The displacement vectors are taken with respect to an previous frame offset of 25. This is used to showcase how the grain boundary atoms are moving, what you’ll see is that its in a cork-screw like manner.\nSince we already have a pipeline and all we want to do is add the displacement vectors and then disable visualizing the particles themselves. I also just want to so the displacement vectors for the grain boundary atoms, so I need to delete the selected particles and then we just need to add a few additional lines of code and then re-render to a new animation file.\n\n\n# Visualization object for vector arrows\nvec_vis = VectorVis(width=0.1,\n                    scaling=1.5,\n                    flat_shading=False,\n                    color=(1,0,0))\n\ndisplacement_mod = CalculateDisplacementsModifier(frame_offset=-25,\n                                                  use_frame_offset=True,\n                                                  vis=vec_vis)\ndisplacement_mod.vis.enabled = True\npipeline.modifiers.append(displacement_mod)\n\n# Need this line to turn off particle visibility\n# Delete elected particles\npipeline.modifiers.append(DeleteSelectedModifier(operate_on={'particles'}))\npipeline.compute(frame=25).particles.vis.enabled = False",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe3.html#step-5-render-second-animation",
    "href": "notebooks/HowToSOVITO_Recipe3.html#step-5-render-second-animation",
    "title": "Recipe 3: Color coding grain boundary atoms",
    "section": "Step 5: Render second animation",
    "text": "Step 5: Render second animation\n\nvp2 = Viewport(type=Viewport.Type.Ortho)\nvp2.camera_dir = [-1, 0, 0]\nvp2.zoom_all()\nfname = \"Cu_Bicrystal_Shear_298K_DisplacementVectors.gif\"\nnframes = pipeline.source.num_frames\nvp2.render_anim(size=(600,400), \n               filename=fname, \n               range=(25,nframes),\n               renderer=renderer)\n\n\ntry:\n    import google.colab\n    from IPython.display import Image\n    Image(open(fname, 'rb').read())\nexcept ImportError:\n    \"Assuming local run.\"\n\n\n\n\n\n\n\nFigure 2: Visualization of displacement vectors for grain boundary.",
    "crumbs": [
      "Recipe 3: Color coding grain boundary atoms"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html",
    "href": "notebooks/HowToSOVITO_Recipe4.html",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "",
    "text": "If you look at the tutorials on the GUI OVITO documentation you find a tutorial showing how to create a turntable animation of a model. If you have access to the Pro OVITO version, they generating the script to batch run this process on several different structures is very straightforward. However, if you only have the Basic OVITO version, you cannot. Therefore having using SOVITO is the only option.\nIn this notebook we are going to recreate almost the same animation but by scripting from scratch.\n%%capture\n! pip install -U ovito\n! pip install imageio",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html#import-ovito-modules",
    "href": "notebooks/HowToSOVITO_Recipe4.html#import-ovito-modules",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "Import OVITO Modules",
    "text": "Import OVITO Modules\n\nfrom ovito.io import import_file\nfrom ovito.modifiers import AffineTransformationModifier\nfrom ovito.pipeline import StaticSource, Pipeline\nfrom ovito.modifiers import PythonScriptModifier\nfrom ovito.vis import TachyonRenderer\nfrom ovito.vis import Viewport\nimport numpy as np\nfrom imageio.v3 import imread\nfrom imageio import mimsave\nimport os",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html#step-1-remote-import-file",
    "href": "notebooks/HowToSOVITO_Recipe4.html#step-1-remote-import-file",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "Step 1: Remote import file",
    "text": "Step 1: Remote import file\n\n\n\n\n\n\nTip\n\n\n\nIn previous tutorials I used command line wget to download the file, however, the import_file function has the ability to do remote fetch simply by using a url\n\n\nWe import the file and then get the data via the compute method of the pipeline for the frame of interest.\n\nremote_file = \"https://gitlab.com/ovito-org/ovito-sample-data/-/raw/04f075def623f25ae1a2d8363a4dcf6e90a0f91a/NetCDF/C60_impact.nc\"\npipeline=import_file(remote_file,input_format=\"netcdf/amber\")\n\nnframes = pipeline.source.num_frames\ndata = pipeline.compute(nframes)",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html#step-2-static-pipeline",
    "href": "notebooks/HowToSOVITO_Recipe4.html#step-2-static-pipeline",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "Step 2: Static pipeline",
    "text": "Step 2: Static pipeline\nNow we create a new, static, pipeline from the data object.\n\nstatic_pipeline = Pipeline(source=StaticSource(data=data))\nstatic_pipeline.add_to_scene()\n\n\nSome code for color coding (optional)\nJust so that the rendered turnable animation is similar to the original version, I’m adding some code here to modify the particle color based on the atomic number, Z.\n\ncolor_map = {\n    1: (1.0, 1.0, 0.0),  # Yellow for Z=1\n    6: (0.2, 0.4, 0.7)   # Blue for Z=6\n}\n\ndef color_particles_based_on_z(frame, data):\n    if 'Color' not in data.particles.keys():\n        data.particles_.create_property('Color', \n                                        data=np.zeros((data.particles.count, 3), \n                                                      dtype=np.float32),\n                                                      )\n    # Access the atomic number property\n    z_property = data.particles['Z'].array  \n    colors = data.particles['Color'].marray\n    \n    # Assign colors based on atomic number using the color map\n    for z, color in color_map.items():\n        mask = (z_property == z)\n        colors[mask] = color\n\n\nstatic_pipeline.modifiers.append(PythonScriptModifier(function=color_particles_based_on_z))",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html#step-3-translating-center-of-rotation",
    "href": "notebooks/HowToSOVITO_Recipe4.html#step-3-translating-center-of-rotation",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "Step 3: Translating center of rotation",
    "text": "Step 3: Translating center of rotation\nAs with the GUI OVITO tutorial, we need to move the rotation center via the AffineTransformationModifier. We specify this translation using the transformation matrix kwarg, where the last column is the translation vector.\n\ntransformation_matrix = [[1.0, 0.0, 0.0, -0.5],\n                         [0.0, 1.0, 0.0, -0.5],\n                         [0.0, 0.0, 1.0, -0.5]]\nstatic_pipeline.modifiers.append(AffineTransformationModifier(\n    transformation=transformation_matrix,\n    reduced_coords=True,  \n    )\n)\n\nstatic_pipeline.compute();",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html#step-4-prepare-viewport",
    "href": "notebooks/HowToSOVITO_Recipe4.html#step-4-prepare-viewport",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "Step 4: Prepare Viewport",
    "text": "Step 4: Prepare Viewport\nOne key difference in the approach used in the GUI OVITO implementation, is we cannot use[^1 At least to my knowledge.] the Viewport.render_anim call because we are not rendering simulation scenes but are just take snapshots of a single scene with a different camera location. Thus we need to write a function to adjust the viewport as we desire. My approach just uses a rotation angle in the x-y plane and then a fixed angle in the azimuthal direction. The distance from the origin is set by r which you can change based on your need.\n\n\n\n\n\n\nNote\n\n\n\nI’m not sure the field of view variable fov does anything here, since it appears this doesn’t mean anything for a Perspective type of view.\n\n\n\nviewport = Viewport(fov=30)\nviewport.type = Viewport.Type.Perspective\n\ndef update_camera_settings(frame, total_frames, r=125):\n    angle = (frame / total_frames) * 2 * np.pi\n    \n    # Calculate the new camera position for the circular orbit\n    rx = r * np.sin(angle)\n    ry = r * np.cos(angle)\n    rz = r / np.sqrt(2) # Camera at 45 degree in z-azimuthal\n    camera_pos = (rx, ry, rz)\n    \n    dir_vector = (-camera_pos[0], -camera_pos[1], -camera_pos[2])\n    # Normalize the direction vector\n    magnitude = np.linalg.norm(dir_vector)\n    camera_dir = (dir_vector[0]/magnitude, dir_vector[1]/magnitude, dir_vector[2]/magnitude)\n    \n    return camera_pos, camera_dir",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe4.html#step-5-render-animation-of-scene",
    "href": "notebooks/HowToSOVITO_Recipe4.html#step-5-render-animation-of-scene",
    "title": "Recipe 4: Recreating turntable animation of a model",
    "section": "Step 5: Render Animation of scene",
    "text": "Step 5: Render Animation of scene\nThe key difference in this animation is that we are moving the camera around the static scene/frame to generate the perspective of a rotating object. To achieve this we loop over the number of camera positions (i.e., animation length) update the camera position and direction vector, render the scene to a temporary image file, and then use the imageio package to create an animation from all the rendered scenes.\n\nanimation_length = 100\nrenderer = TachyonRenderer(\n    ambient_occlusion=True,  \n    ambient_occlusion_brightness=0.8,  \n    antialiasing=True,  \n    antialiasing_samples=64,  \n    direct_light=True,  \n    direct_light_intensity=0.9, \n    shadows=True,  \n    depth_of_field=False, \n    focal_length=40.0,  \n    aperture=0.01  \n)\nimage_paths = []\n\nfor frame in range(animation_length):\n    camera_pos, camera_dir = update_camera_settings(frame, animation_length)\n    viewport.camera_pos = camera_pos\n    viewport.camera_dir = camera_dir\n    \n    filename = f\"temp_frame_{frame:04d}.png\"\n    image_paths.append(filename)  # Store for later deletion\n    viewport.render_image(filename=filename, size=(600, 400), renderer=renderer)\n\n# Create a GIF from the images\ngif_filename = 'recipe4_animation.gif'\nimages = [imread(filename) for filename in image_paths]\nmimsave(gif_filename, images, fps=25, loop=0)\n\n# Delete the temporary images\nfor filename in image_paths:\n    os.remove(filename)\n\n\ntry:\n    import google.colab\n    from IPython.display import Image\n    Image(open(fname, 'rb').read())\nexcept ImportError:\n    \"Assuming local run.\"\n\n\n\n\n\n\n\nFigure 1: Reproducing the turnable animation in the OVITO Basic GUI tutorial.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nA few things to note:\n\nThe perspective view is a little different from that shown in the original mainly because I’m not exactly sure the settings of the camera. You will need to adjust the settings based on your data.\nIn my opinion this recipe may bit a bit unessecary, because with OVITO 3.10 and above you can use the glTF format which creates 3D models that can be animated to rotate and are manipulatable. Furthermore, you can use the ovito_to_ase call to create an ASE Atoms object and then use ASE io to save to html and use X3DOM (Bringuier 2024).",
    "crumbs": [
      "Recipe 4: Recreating turntable animation of a model"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html",
    "href": "notebooks/HowToSOVITO_Recipe2.html",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "",
    "text": "Frequently you’ll want to know what the distribution is of structural quantities. For example you may want to know where the average first nearest neighbor is or the bond-angle formed by a pair os nearest neighbors. This reciepe will allow you to 1.) perform the analysis, 2.) add the plots to the rendered scene.\n%%capture\n! pip install -U ovito",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#import-ovito-modules-and-matplotlib",
    "href": "notebooks/HowToSOVITO_Recipe2.html#import-ovito-modules-and-matplotlib",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Import OVITO modules and Matplotlib",
    "text": "Import OVITO modules and Matplotlib\n\nfrom ovito.io import import_file\nfrom ovito.modifiers import CreateBondsModifier, BondAnalysisModifier, CoordinationAnalysisModifier\nfrom ovito.vis import Viewport, PythonViewportOverlay\nfrom ovito.vis import ViewportOverlayInterface\nfrom ovito.vis import TachyonRenderer, OSPRayRenderer, OpenGLRenderer\nfrom PySide6.QtGui import QImage, QPainter\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#step-1-download-lammps-dump-and-create-ovito-pipeline",
    "href": "notebooks/HowToSOVITO_Recipe2.html#step-1-download-lammps-dump-and-create-ovito-pipeline",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Step 1: Download LAMMPS dump and create OVITO pipeline",
    "text": "Step 1: Download LAMMPS dump and create OVITO pipeline\nAs usually load your file into a OVITO pipeline and the nadd it to scene.\n\n%%capture\n! wget  'https://drive.google.com/uc?id=1GZS1AOqJHYe4TVgqfkWR1YbRdYrPBPqB&export=download' -O dump.nacl-melt\npipeline = import_file('dump.nacl-melt')\npipeline.add_to_scene()",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#step-2-functions-for-bad-and-rdf",
    "href": "notebooks/HowToSOVITO_Recipe2.html#step-2-functions-for-bad-and-rdf",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Step 2: Functions for BAD and RDF",
    "text": "Step 2: Functions for BAD and RDF\nPlotting using matplotlib is handled as normal python code. The main thing is using the OVITO calculated data (see below). Here we define the matplotlib plotting functions for the radial distribution function (RDF) and the bond-angle distribution (BAD). These will get used by the Overlay class.\n\n\n\n\n\n\nTip\n\n\n\nNote, that if you know something about the range of values for the y and x axis, you would modify that here, so that during animations the “flickering” of the plots is limited. I haven’t done so here.\n\n\n\ndef plot_bond_angle_distribution(data):\n    plt.figure(figsize=(5/2,3.5/2))\n    plt.bar(data[:,0], data[:,1], width=data[1,0]-data[0,0], align='center')\n    plt.xlabel('Bond angle (degrees)', fontsize=8)\n    plt.ylabel('Count', fontsize=8)\n    ax = plt.gca()\n    ax.tick_params(axis='both', which='major', labelsize=6, direction='in')\n    ax.set_ylim(0.0,300)\n    ax.xaxis.set_major_locator(ticker.AutoLocator())\n    ax.yaxis.set_major_locator(ticker.AutoLocator())\n    plt.tight_layout()\n    plt.savefig('bond_angle_plot.png', dpi=300, transparent=True)\n    plt.close()\n\ndef plot_radial_distribution_function(data):\n    plt.figure(figsize=(5/2, 3.5/2))\n    plt.plot(data[:,0], data[:,1])\n    plt.xlabel('Distance', fontsize=8)\n    plt.ylabel('g(r)', fontsize=8)\n    ax = plt.gca()\n    ax.tick_params(axis='both', which='major', labelsize=6, direction='in')\n    ax.set_xlim(0.0,None)\n    ax.set_ylim(0.0,5.0)\n    plt.tight_layout()\n    plt.savefig('rdf_plot.png', dpi=300, transparent=True)\n    plt.close()",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#step-3-class-for-viewport-overlay-of-rdf-and-bad-plots",
    "href": "notebooks/HowToSOVITO_Recipe2.html#step-3-class-for-viewport-overlay-of-rdf-and-bad-plots",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Step 3: Class for Viewport Overlay of RDF and BAD plots",
    "text": "Step 3: Class for Viewport Overlay of RDF and BAD plots\nNow we define a Overlay class that has a method called render. This gets called when a Viewport object is rendered.\nNotice that we have our pipeline.compute here, so all the modifiers that are set in a pipelien get called. We also cal our plotting functions and then open a canvas to add the plots to the scene.\n\nclass Overlay(ViewportOverlayInterface):\n    def render(self, canvas, **kwargs):\n      frame = kwargs['frame']\n      data = pipeline.compute(frame=frame)\n      plot_radial_distribution_function(data.tables['coordination-rdf'].xy())\n      plot_bond_angle_distribution(data.tables['bond-angle-distr'].xy())\n      with canvas.qt_painter() as painter:\n        bond_angle_image = QImage('bond_angle_plot.png')\n        rdf_image = QImage('rdf_plot.png')\n        # Define the position and size of the images on the canvas\n        bond_angle_pos = (1.0, 1.0)  # right-top corner\n        rdf_pos = (1.0, 0.0)         # right-bottom corner\n        size = (0.45, 0.45)          # fractional coordinates\n        canvas.draw_image(bond_angle_image, pos=bond_angle_pos, size=size, anchor=\"north east\")\n        canvas.draw_image(rdf_image, pos=rdf_pos, size=size, anchor=\"south east\")",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#step-4-ovito-modifiers",
    "href": "notebooks/HowToSOVITO_Recipe2.html#step-4-ovito-modifiers",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Step 4: OVITO Modifiers",
    "text": "Step 4: OVITO Modifiers\nOVITO modifiers are analysis or property calculation/setting routines. For anything you want to do, in terms of analyzing your data from a atomistic simulation, you will use a modifier which is appended to the pipeline via pipeline.modifiers.append(...). Here the modifiers we use are the BondAnalysisModifier and CoordinationAnalysisModifier to grab the data for plotting the BAD and RDF.\n\n# Create bonds if not already in the dump\npipeline.modifiers.append(CreateBondsModifier(cutoff=3.5))\n\n# Calculate the bond-angle distribution\nbond_angle_modifier = BondAnalysisModifier()\npipeline.modifiers.append(bond_angle_modifier)\n\n# Calculate the radial distribution function\nrdf_modifier = CoordinationAnalysisModifier(cutoff=6.5, number_of_bins=100)\npipeline.modifiers.append(rdf_modifier)",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#step-5-viewport-and-render",
    "href": "notebooks/HowToSOVITO_Recipe2.html#step-5-viewport-and-render",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Step 5: Viewport and Render",
    "text": "Step 5: Viewport and Render\nAs usually we need to create our Viewport object and then configure it based on how we want to view the scene.\nThen because we are overlaying additional images that have been created by matplotlib we need to provide our overlay object to the viewport. Then we add the pipeline to the scene.\n\nviewport = Viewport(type=Viewport.Type.Ortho, camera_dir=(2, 1, -1))\nviewport.zoom_all()\nviewport.camera_pos = [15, -1, 15]\n\noverlay = PythonViewportOverlay(delegate=Overlay())\nviewport.overlays.append(overlay)\n\npipeline.add_to_scene();\n\n\n\n\n\n\n\nNote\n\n\n\nWe just use the code below to display an image in a notebook.\n\n\n\nfrom IPython.display import Image\n\n\nRender Single Frame\n\n# Render image\nframe=9\nfstatic = f'nacl_melt_rendered_frame_{frame}.png'\nviewport.render_image(size=(800, 600),\n                      frame=frame,\n                      filename=fstatic,\n                      renderer=OSPRayRenderer());\n\n\nImage(open(fstatic, 'rb').read())\n\n\n\n\n\n\n\nFigure 1: NaCl melt with corresponding BAD and RDF.",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe2.html#animation",
    "href": "notebooks/HowToSOVITO_Recipe2.html#animation",
    "title": "Recipe 2: Plotting RDF and BAD with rendered scene",
    "section": "Animation",
    "text": "Animation\n\nfanim = 'nacl_melt_animation.gif'\nviewport.render_anim(size=(800, 600),\n                     every_nth=5,\n                     filename=fanim,\n                     renderer=OSPRayRenderer(),\n                     fps=10)\n\n\n\n\n\n\n\nFigure 2: Simulation of NaCl visual with RDF and BAD.",
    "crumbs": [
      "Recipe 2: Plotting RDF and BAD with rendered scene"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe1.html",
    "href": "notebooks/HowToSOVITO_Recipe1.html",
    "title": "Recipe 1: Simple import and visualization",
    "section": "",
    "text": "%%capture\n! pip install -U ovito",
    "crumbs": [
      "Recipe 1: Simple import and visualization"
    ]
  },
  {
    "objectID": "notebooks/HowToSOVITO_Recipe1.html#optional-save-a-3d-model",
    "href": "notebooks/HowToSOVITO_Recipe1.html#optional-save-a-3d-model",
    "title": "Recipe 1: Simple import and visualization",
    "section": "Optional: Save a 3D Model",
    "text": "Optional: Save a 3D Model\nA nice feature is we can save a 3D model representation of our frame/viewport and then manipulate it in real-time in a browser or powerpoint.\n\nexport_file(pipeline,file=\"FCC-C60-Pillar.glb\",format=\"gltf\")",
    "crumbs": [
      "Recipe 1: Simple import and visualization"
    ]
  }
]